# Phoenix & Langfuse å¯è§‚æµ‹æ€§æ¶æ„æµç¨‹å›¾

## ç³»ç»Ÿæ¶æ„æ¦‚è§ˆ

æœ¬æ–‡æ¡£è¯¦ç»†è¯´æ˜ KnowledgeWeaver é¡¹ç›®ä¸­ Phoenix å’Œ Langfuse ä¸¤ä¸ªå¯è§‚æµ‹æ€§å·¥å…·çš„è¿ä½œæœºåˆ¶å’Œæ•°æ®æµå‘ã€‚

## æœ¬è´¨ï¼šä»£ç†/ç½‘å…³æ¨¡å¼

**ç®€å•ç†è§£**ï¼šPhoenix å’Œ Langfuse æœ¬è´¨ä¸Šéƒ½æ˜¯åœ¨åº”ç”¨å’Œ LLM API ä¹‹é—´åŠ äº†ä¸€å±‚"ç½‘å…³"ï¼Œç”¨äºè§‚æµ‹å’Œè®°å½•æ‰€æœ‰æµé‡ã€‚

```mermaid
graph LR
    subgraph "æ— ç›‘æ§æ—¶"
        App1[åº”ç”¨ä»£ç ] -->|ç›´æ¥è°ƒç”¨| LLM1[LLM API]
    end

    subgraph "åŠ å…¥ç›‘æ§å"
        App2[åº”ç”¨ä»£ç ] -->|è°ƒç”¨| Gateway{ç›‘æ§ç½‘å…³å±‚}
        Gateway -->|1. è®°å½•è¯·æ±‚| Monitor[ç›‘æ§ç³»ç»Ÿ]
        Gateway -->|2. è½¬å‘è°ƒç”¨| LLM2[LLM API]
        LLM2 -->|3. è¿”å›ç»“æœ| Gateway
        Gateway -->|4. è®°å½•å“åº”| Monitor
        Gateway -->|5. è¿”å›| App2
    end

    style Gateway fill:#fff4e1
    style Monitor fill:#d4edda
```

### ä¸¤ç§ç½‘å…³å®ç°æ–¹å¼

```mermaid
graph TB
    subgraph "Langfuse: ä»£ç†æ¨¡å¼ (Proxy Pattern)"
        Code1[ä½ çš„ä»£ç ] -->|è°ƒç”¨| Wrapper[Langfuse Wrapper]
        Wrapper -->|æ‹¦æˆª| Record1[è®°å½•è¿½è¸ªæ•°æ®]
        Wrapper -->|è½¬å‘| Original1[åŸå§‹ OpenAI å®¢æˆ·ç«¯]
        Original1 -->|è°ƒç”¨| API1[LLM API]
        API1 -->|å“åº”| Original1
        Original1 -->|è¿”å›| Wrapper
        Wrapper -->|è®°å½•| Record1
        Wrapper -->|è¿”å›| Code1
    end

    subgraph "Phoenix: AOP åˆ‡é¢æ¨¡å¼ (Aspect-Oriented)"
        Code2[ä½ çš„ä»£ç ] -->|è°ƒç”¨| Instrumented[å·²æ³¨å…¥çš„ OpenAI ç±»]
        Instrumented -->|è°ƒç”¨å‰é’©å­| Before[Before Hook]
        Before -->|è®°å½•| Record2[åˆ›å»º Span]
        Instrumented -->|åŸå§‹è°ƒç”¨| API2[LLM API]
        API2 -->|å“åº”| Instrumented
        Instrumented -->|è°ƒç”¨åé’©å­| After[After Hook]
        After -->|è®°å½•| Record2
        Instrumented -->|è¿”å›| Code2
    end

    style Wrapper fill:#ffe1f5
    style Instrumented fill:#e1f5ff
    style Record1 fill:#d4edda
    style Record2 fill:#d4edda
```

### ç±»æ¯”ç†è§£

| æ¦‚å¿µ | ä¼ ç»Ÿç½‘ç»œ | å¯è§‚æµ‹æ€§ |
|------|---------|---------|
| **åŸå§‹æµé‡** | å®¢æˆ·ç«¯ â†’ æœåŠ¡å™¨ | åº”ç”¨ â†’ LLM API |
| **ç½‘å…³å±‚** | API Gateway / Nginx | Phoenix / Langfuse |
| **åŠŸèƒ½** | è·¯ç”±ã€é™æµã€é‰´æƒ | è¿½è¸ªã€è®°å½•ã€åˆ†æ |
| **å®ç°** | ç½‘ç»œå±‚ä»£ç† | ä»£ç å±‚åŒ…è£…/æ³¨å…¥ |
| **é€æ˜æ€§** | å¯¹å®¢æˆ·ç«¯é€æ˜ | å¯¹ä¸šåŠ¡ä»£ç é€æ˜ |

**å…³é”®åŒºåˆ«**ï¼š
- **Langfuse**: æ˜¾å¼åŒ…è£… `client = wrapper.wrap(client)`ï¼Œåƒæ˜¯ä¸»åŠ¨æ¥å…¥ç½‘å…³
- **Phoenix**: è‡ªåŠ¨æ³¨å…¥ `instrument()`ï¼Œåƒæ˜¯ç½‘å…³è‡ªåŠ¨æ‹¦æˆªæµé‡

## å®Œæ•´æ•°æ®æµç¨‹å›¾

```mermaid
graph TB
    subgraph "å®¢æˆ·ç«¯è¯·æ±‚"
        User[ç”¨æˆ·/åº”ç”¨] -->|HTTP Request| API[FastAPI æœåŠ¡å™¨]
    end

    subgraph "Session è¿½è¸ªä¸­é—´ä»¶"
        API --> SessionMW[Session Middleware]
        SessionMW -->|1. æå–/ç”Ÿæˆ session_id| SessionStart[Phoenix: start_session]
        SessionMW -->|2. æ”¶é›†å…ƒæ•°æ®| Metadata[è·¯å¾„/æ–¹æ³•/IP/User-Agent]
        SessionStart --> CTX[ContextVar å­˜å‚¨]
        Metadata --> CTX
    end

    subgraph "ä¸šåŠ¡å¤„ç†å±‚"
        SessionMW -->|3. è½¬å‘è¯·æ±‚| Handler[è¯·æ±‚å¤„ç†å™¨]
        Handler --> QA[QA Engine]
        Handler --> DOC[æ–‡æ¡£ä¸Šä¼ ]
        Handler --> GRAPH[å›¾è°±æŸ¥è¯¢]
    end

    subgraph "QA å¼•æ“ - LLM è°ƒç”¨"
        QA -->|4. åˆå§‹åŒ–| Client[OpenAI Client]
        Client -->|5a. Langfuse Wrapper| LFClient[Langfuse-wrapped Client]
        LFClient -->|6. è°ƒç”¨ LLM| LLM[LLM API<br/>DeepSeek/GPT-4]
    end

    subgraph "Phoenix è¿½è¸ª (OpenTelemetry)"
        Client -.->|è‡ªåŠ¨ instrument| OTel[OpenTelemetry<br/>Auto Instrumentation]
        OTel -.->|è®°å½• span| Tracer[Phoenix Tracer Provider]
        CTX -.->|æ·»åŠ  session å±æ€§| Tracer
        Tracer -.->|å¯¼å‡ºæ•°æ®| Collector[Phoenix Collector<br/>localhost:4317]
        Collector -.->|å­˜å‚¨| PhoenixDB[(Phoenix æœ¬åœ°å­˜å‚¨)]
    end

    subgraph "Langfuse è¿½è¸ª (Wrapper)"
        LFClient -->|æ‹¦æˆªè°ƒç”¨| LFTrace[Langfuse Trace]
        LFTrace -->|è®°å½•å…ƒæ•°æ®| LFMeta[Prompt/Response<br/>Token/Cost/Latency]
        LFMeta -->|å¼‚æ­¥å‘é€| LFCollector[Langfuse Collector]
        LFCollector -->|å­˜å‚¨| LangfuseDB[(Langfuse äº‘ç«¯/è‡ªæ‰˜ç®¡)]
    end

    subgraph "å“åº”è¿”å›"
        LLM -->|7. è¿”å›ç»“æœ| LFClient
        LFClient -->|8. è¿”å›| QA
        QA -->|9. æ„å»ºå“åº”| Response[QA Response]
        Response -->|10. æ·»åŠ  session_id header| SessionMW
        SessionMW -->|11. æ¸…ç† ContextVar| SessionEnd[end_session]
        SessionMW -->|12. HTTP Response| User
    end

    subgraph "å¯è§‚æµ‹æ€§ UI"
        PhoenixDB -.->|æŸ¥çœ‹| PhoenixUI[Phoenix UI<br/>localhost:6006]
        LangfuseDB -.->|æŸ¥çœ‹| LangfuseUI[Langfuse UI<br/>cloud/self-hosted]
    end

    style SessionMW fill:#e1f5ff
    style OTel fill:#fff4e1
    style LFTrace fill:#ffe1f5
    style PhoenixUI fill:#d4edda
    style LangfuseUI fill:#d4edda
```

## Phoenix å·¥ä½œåŸç†

### 1. åˆå§‹åŒ–é˜¶æ®µ

```mermaid
sequenceDiagram
    participant App as åº”ç”¨å¯åŠ¨
    participant PT as PhoenixTracer
    participant Reg as Phoenix Register
    participant OTel as OpenTelemetry
    participant Inst as OpenAI Instrumentor

    App->>PT: get_phoenix_tracer()
    PT->>PT: æ£€æŸ¥ PHOENIX_ENABLED
    alt Phoenix å¯ç”¨
        PT->>Reg: register(project_name, endpoint)
        Reg->>OTel: é…ç½® TracerProvider
        OTel-->>PT: è¿”å› tracer_provider
        PT->>Inst: instrument(tracer_provider)
        Inst->>Inst: è‡ªåŠ¨åŒ…è£… OpenAI ç±»
        Inst-->>PT: âœ… å®Œæˆ
        PT-->>App: âœ… Phoenix å·²å¯ç”¨
    else Phoenix ç¦ç”¨
        PT-->>App: â„¹ï¸ Phoenix å·²ç¦ç”¨
    end
```

### 2. Session è¿½è¸ªæµç¨‹

```mermaid
sequenceDiagram
    participant Req as HTTP è¯·æ±‚
    participant MW as Session Middleware
    participant PT as PhoenixTracer
    participant CTX as ContextVar
    participant Handler as è¯·æ±‚å¤„ç†å™¨
    participant Span as OpenTelemetry Span

    Req->>MW: åˆ°è¾¾è¯·æ±‚
    MW->>MW: æå– X-Session-ID header
    alt æ²¡æœ‰ session_id
        MW->>PT: start_session()
        PT->>PT: ç”Ÿæˆ UUID
    else æœ‰ session_id
        MW->>PT: start_session(existing_id)
    end

    PT->>CTX: è®¾ç½® session_id + metadata
    MW->>Handler: è½¬å‘è¯·æ±‚

    Handler->>Handler: æ‰§è¡Œä¸šåŠ¡é€»è¾‘
    Handler->>Span: åˆ›å»º span (è‡ªåŠ¨)
    Span->>CTX: è¯»å– session.id
    Span->>Span: set_attribute("session.id", ...)
    Span->>Span: set_attribute("session.path", ...)

    Handler-->>MW: è¿”å›å“åº”
    MW->>MW: æ·»åŠ  X-Session-ID åˆ°å“åº”å¤´
    MW->>PT: end_session()
    PT->>CTX: æ¸…ç† ContextVar
    MW-->>Req: è¿”å›å“åº”
```

### 3. è‡ªåŠ¨è¿½è¸ªæœºåˆ¶

```mermaid
graph LR
    subgraph "åº”ç”¨ä»£ç  (æ— ä¿®æ”¹)"
        Code[client.chat.completions.create]
    end

    subgraph "OpenAI Instrumentor (è‡ªåŠ¨æ³¨å…¥)"
        Wrap[åŒ…è£… OpenAI ç±»]
        Before[è°ƒç”¨å‰ Hook]
        After[è°ƒç”¨å Hook]
    end

    subgraph "OpenTelemetry"
        Span[åˆ›å»º Span]
        Attrs[è®°å½•å±æ€§]
        Export[å¯¼å‡ºåˆ° Collector]
    end

    Code -->|è°ƒç”¨| Wrap
    Wrap --> Before
    Before --> Span
    Span --> Attrs
    Attrs -.->|model, messages, temperature| Span
    Before -->|å®é™…è°ƒç”¨| LLM[LLM API]
    LLM --> After
    After -.->|response, tokens, latency| Span
    Span --> Export
    Export --> Collector[(Phoenix Collector)]

    style Code fill:#e1f5ff
    style Wrap fill:#fff4e1
    style Span fill:#ffe1f5
```

## Langfuse å·¥ä½œåŸç†

### 1. åˆå§‹åŒ–å’ŒåŒ…è£…

```mermaid
sequenceDiagram
    participant QA as QA Engine
    participant LFT as LangfuseTracer
    participant LF as Langfuse Client
    participant Client as OpenAI Client
    participant Wrapper as LangfuseOpenAI

    QA->>Client: åˆ›å»º OpenAI å®¢æˆ·ç«¯
    QA->>LFT: get_tracer()
    LFT->>LFT: æ£€æŸ¥ LANGFUSE_ENABLED

    alt Langfuse å¯ç”¨
        LFT->>LF: åˆå§‹åŒ– Langfuse å®¢æˆ·ç«¯
        LF-->>LFT: å®¢æˆ·ç«¯å®ä¾‹
        QA->>LFT: wrap_openai(client)
        LFT->>Wrapper: åˆ›å»º LangfuseOpenAI
        Wrapper->>Wrapper: ç»§æ‰¿é…ç½® (base_url, api_key)
        Wrapper-->>LFT: åŒ…è£…åçš„å®¢æˆ·ç«¯
        LFT-->>QA: âœ… è¿”å›åŒ…è£…å®¢æˆ·ç«¯
    else Langfuse ç¦ç”¨
        LFT-->>QA: â„¹ï¸ è¿”å›åŸå§‹å®¢æˆ·ç«¯
    end
```

### 2. LLM è°ƒç”¨è¿½è¸ª

```mermaid
sequenceDiagram
    participant Code as åº”ç”¨ä»£ç 
    participant Wrapper as LangfuseOpenAI
    participant LF as Langfuse Client
    participant LLM as LLM API
    participant Backend as Langfuse åç«¯

    Code->>Wrapper: chat.completions.create(...)
    Wrapper->>Wrapper: åˆ›å»º Trace å¯¹è±¡
    Wrapper->>Wrapper: è®°å½• input (messages)
    Wrapper->>Wrapper: å¼€å§‹è®¡æ—¶

    Wrapper->>LLM: è½¬å‘è°ƒç”¨
    LLM-->>Wrapper: è¿”å›å“åº”

    Wrapper->>Wrapper: åœæ­¢è®¡æ—¶
    Wrapper->>Wrapper: è®°å½• output (response)
    Wrapper->>Wrapper: è®¡ç®— tokens å’Œ cost

    Wrapper->>LF: åˆ›å»º trace è®°å½•
    LF->>LF: ç¼“å­˜åˆ°å†…å­˜é˜Ÿåˆ—

    par å¼‚æ­¥å‘é€
        LF->>Backend: æ‰¹é‡å‘é€ traces
        Backend-->>LF: âœ… ç¡®è®¤
    end

    Wrapper-->>Code: è¿”å›å“åº”
```

### 3. Flush æœºåˆ¶

```mermaid
graph TB
    subgraph "åº”ç”¨ç”Ÿå‘½å‘¨æœŸ"
        Start[åº”ç”¨å¯åŠ¨] --> Run[æ­£å¸¸è¿è¡Œ]
        Run --> Shutdown[åº”ç”¨å…³é—­]
    end

    subgraph "Langfuse ç¼“å†²æœºåˆ¶"
        Call[LLM è°ƒç”¨] -->|è®°å½•| Queue[å†…å­˜é˜Ÿåˆ—]
        Queue -->|æ¡ä»¶è§¦å‘| Flush{éœ€è¦ Flush?}
        Flush -->|1. é˜Ÿåˆ—æ»¡| Send[å‘é€åˆ°åç«¯]
        Flush -->|2. å®šæ—¶å™¨| Send
        Flush -->|3. æ‰‹åŠ¨ flush| Send
        Flush -->|4. åº”ç”¨é€€å‡º| Send
        Send --> Backend[(Langfuse åç«¯)]
    end

    Shutdown -.->|è§¦å‘| Flush

    style Queue fill:#fff4e1
    style Send fill:#ffe1f5
```

## æ•°æ®å¯¹æ¯”

### Phoenix vs Langfuse è®°å½•å†…å®¹

```mermaid
graph LR
    subgraph "LLM è°ƒç”¨"
        Call[OpenAI API Call]
    end

    subgraph "Phoenix è®°å½•"
        P1[æŠ€æœ¯æŒ‡æ ‡]
        P2[Trace/Span ID]
        P3[Session ID]
        P4[å»¶è¿Ÿæ—¶é—´]
        P5[Token è®¡æ•°]
        P6[Prompt/Response]
        P7[æ¨¡å‹å‚æ•°]
    end

    subgraph "Langfuse è®°å½•"
        L1[ä¸šåŠ¡æŒ‡æ ‡]
        L2[Trace ID]
        L3[ç”¨æˆ· ID optional]
        L4[å»¶è¿Ÿæ—¶é—´]
        L5[Token + Cost]
        L6[Prompt/Response]
        L7[æ¨¡å‹å‚æ•°]
        L8[æ ‡ç­¾/å…ƒæ•°æ®]
    end

    Call -.-> P1
    Call -.-> P2
    Call -.-> P3
    Call -.-> P4
    Call -.-> P5
    Call -.-> P6
    Call -.-> P7

    Call -.-> L1
    Call -.-> L2
    Call -.-> L3
    Call -.-> L4
    Call -.-> L5
    Call -.-> L6
    Call -.-> L7
    Call -.-> L8

    style P1 fill:#e1f5ff
    style L1 fill:#ffe1f5
```

### æ•°æ®æµå‘å¯¹æ¯”

```mermaid
graph TB
    subgraph "åº”ç”¨å±‚"
        App[FastAPI åº”ç”¨]
    end

    subgraph "Phoenix æ•°æ®æµ"
        App -->|OpenTelemetry| OTLP[OTLP Exporter]
        OTLP -->|gRPC :4317| PC[Phoenix Collector]
        PC --> PDB[(æœ¬åœ°å­˜å‚¨)]
        PDB --> PUI[Phoenix UI :6006]
    end

    subgraph "Langfuse æ•°æ®æµ"
        App -->|Wrapper æ‹¦æˆª| LFQ[å†…å­˜é˜Ÿåˆ—]
        LFQ -->|æ‰¹é‡å‘é€| LFAPI[Langfuse API]
        LFAPI --> LFDB[(äº‘ç«¯/è‡ªæ‰˜ç®¡ DB)]
        LFDB --> LFUI[Langfuse UI :3000]
    end

    style PC fill:#d4edda
    style LFAPI fill:#f8d7da
```

## Session è¿½è¸ªè¯¦è§£

### Session ç”Ÿå‘½å‘¨æœŸ

```mermaid
stateDiagram-v2
    [*] --> åˆ›å»º: HTTP è¯·æ±‚åˆ°è¾¾
    åˆ›å»º --> æ´»è·ƒ: start_session()
    æ´»è·ƒ --> æ´»è·ƒ: ä¸šåŠ¡å¤„ç†<br/>LLM è°ƒç”¨
    æ´»è·ƒ --> æ¸…ç†: è¯·æ±‚å¤„ç†å®Œæˆ
    æ¸…ç† --> [*]: end_session()

    note right of åˆ›å»º
        1. æå–/ç”Ÿæˆ session_id
        2. æ”¶é›†å…ƒæ•°æ®
        3. å­˜å‚¨åˆ° ContextVar
    end note

    note right of æ´»è·ƒ
        æ‰€æœ‰ span è‡ªåŠ¨å…³è”
        session.id å±æ€§
    end note

    note right of æ¸…ç†
        æ¸…ç† ContextVar
        ä¿ç•™å·²åˆ›å»ºçš„ span
    end note
```

### Session åœ¨ Phoenix ä¸­çš„ä½“ç°

```mermaid
graph TB
    subgraph "Phoenix UI"
        Projects[é¡¹ç›®åˆ—è¡¨] --> KW[knowledge-weaver]
        KW --> Traces[Traces é¡µé¢]
        Traces --> Filter[æŒ‰ session.id ç­›é€‰]
    end

    subgraph "å•ä¸ª Session çš„ Trace"
        Filter --> Session[Session: 550e8400-...]
        Session --> Span1[Span: /qa - é—®é¢˜1]
        Session --> Span2[Span: /qa - é—®é¢˜2]
        Session --> Span3[Span: /qa - é—®é¢˜3]

        Span1 --> LLM1[LLM Call 1]
        Span2 --> LLM2[LLM Call 2]
        Span3 --> LLM3[LLM Call 3]
    end

    subgraph "Span å±æ€§"
        LLM1 -.->|session.id| SID[550e8400-...]
        LLM1 -.->|session.path| PATH[/qa]
        LLM1 -.->|session.method| METHOD[POST]
        LLM1 -.->|session.client_ip| IP[192.168.1.100]
    end

    style Session fill:#d4edda
    style SID fill:#e1f5ff
```

## é…ç½®æµç¨‹

### å¯ç”¨æµç¨‹å›¾

```mermaid
graph TB
    Start[å¼€å§‹] --> CheckEnv{æ£€æŸ¥ç¯å¢ƒ}

    CheckEnv -->|å¼€å‘ç¯å¢ƒ| DevConfig[dev.env]
    CheckEnv -->|æµ‹è¯•ç¯å¢ƒ| TestConfig[test.env]
    CheckEnv -->|ç”Ÿäº§ç¯å¢ƒ| ProdConfig[prod.env]

    DevConfig --> Phoenix1[PHOENIX_ENABLED=true]
    DevConfig --> Langfuse1[LANGFUSE_ENABLED=false]

    TestConfig --> Phoenix2[PHOENIX_ENABLED=true]
    TestConfig --> Langfuse2[LANGFUSE_ENABLED=true]

    ProdConfig --> Phoenix3[PHOENIX_ENABLED=false<br/>æˆ– SAMPLING_RATE=0.05]
    ProdConfig --> Langfuse3[LANGFUSE_ENABLED=true]

    Phoenix1 --> DevRun[å¼€å‘: å®éªŒ + ä¼˜åŒ–]
    Langfuse1 --> DevRun

    Phoenix2 --> TestRun[æµ‹è¯•: åŒé‡ç›‘æ§]
    Langfuse2 --> TestRun

    Phoenix3 --> ProdRun[ç”Ÿäº§: ä¸»è¦ç”¨ Langfuse]
    Langfuse3 --> ProdRun

    style DevConfig fill:#e1f5ff
    style TestConfig fill:#fff4e1
    style ProdConfig fill:#ffe1f5
```

## ä½¿ç”¨åœºæ™¯æµç¨‹

### åœºæ™¯ 1: æ–°åŠŸèƒ½å¼€å‘

```mermaid
sequenceDiagram
    participant Dev as å¼€å‘è€…
    participant Code as ä»£ç 
    participant Phoenix as Phoenix
    participant PUI as Phoenix UI

    Dev->>Code: ç¼–å†™æ–°åŠŸèƒ½
    Code->>Phoenix: è‡ªåŠ¨è¿½è¸ª
    Dev->>PUI: æ‰“å¼€ Playground

    loop è¿­ä»£ä¼˜åŒ–
        Dev->>PUI: ä¿®æ”¹ Prompt
        PUI->>Phoenix: æµ‹è¯•è°ƒç”¨
        Phoenix-->>PUI: è¿”å›ç»“æœ
        Dev->>Dev: å¯¹æ¯”æ•ˆæœ
    end

    Dev->>Phoenix: è¿è¡Œè¯„ä¼°
    Phoenix-->>Dev: å‡†ç¡®ç‡ 92%
    Dev->>Code: âœ… éƒ¨ç½²åˆ°ç”Ÿäº§
```

### åœºæ™¯ 2: ç”Ÿäº§é—®é¢˜è¯Šæ–­

```mermaid
sequenceDiagram
    participant User as ç”¨æˆ·åé¦ˆ
    participant LF as Langfuse
    participant Dev as å¼€å‘è€…
    participant Phoenix as Phoenix

    User->>LF: é—®é¢˜æŠ¥å‘Š
    Dev->>LF: æŸ¥çœ‹ Traces
    LF-->>Dev: å‘ç°å¼‚å¸¸æ¨¡å¼
    Dev->>Dev: å¯¼å‡ºé—®é¢˜æ•°æ®

    Dev->>Phoenix: åœ¨å¼€å‘ç¯å¢ƒé‡ç°
    Phoenix-->>Dev: è¯¦ç»†è¯Šæ–­ä¿¡æ¯
    Dev->>Dev: å®šä½æ ¹å› 
    Dev->>Code: ä¿®å¤ä»£ç 

    Code->>Phoenix: éªŒè¯ä¿®å¤
    Phoenix-->>Dev: âœ… é—®é¢˜è§£å†³
    Dev->>Production: éƒ¨ç½²ä¿®å¤
    Production->>LF: ç›‘æ§æ•ˆæœ
    LF-->>Dev: âœ… é”™è¯¯ç‡ä¸‹é™
```

### åœºæ™¯ 3: æˆæœ¬ä¼˜åŒ–

```mermaid
graph TB
    Start[Langfuse å‘Šè­¦: æˆæœ¬è¿‡é«˜] --> Analysis[åˆ†ææˆæœ¬åˆ†å¸ƒ]
    Analysis --> Identify[å®šä½é«˜æˆæœ¬åŠŸèƒ½]
    Identify --> Phoenix[åœ¨ Phoenix ä¸­å®éªŒ]

    Phoenix --> Option1[æ–¹æ¡ˆ A: çŸ­ä¸Šä¸‹æ–‡]
    Phoenix --> Option2[æ–¹æ¡ˆ B: ä¾¿å®œæ¨¡å‹]
    Phoenix --> Option3[æ–¹æ¡ˆ C: ç¼“å­˜ç»“æœ]

    Option1 --> Eval[è¯„ä¼°æµ‹è¯•]
    Option2 --> Eval
    Option3 --> Eval

    Eval --> Compare[å¯¹æ¯”è´¨é‡å’Œæˆæœ¬]
    Compare --> Select[é€‰æ‹©æœ€ä½³æ–¹æ¡ˆ]
    Select --> Deploy[éƒ¨ç½²åˆ°ç”Ÿäº§]
    Deploy --> Verify[Langfuse éªŒè¯]
    Verify --> Success{æˆæœ¬é™ä½?}

    Success -->|æ˜¯| End[âœ… ä¼˜åŒ–å®Œæˆ]
    Success -->|å¦| Phoenix

    style Start fill:#f8d7da
    style Phoenix fill:#d4edda
    style Success fill:#fff4e1
    style End fill:#d4edda
```

## æ€§èƒ½å¼€é”€å¯¹æ¯”

```mermaid
graph LR
    subgraph "åŸºå‡†æ€§èƒ½"
        Base[æ— ç›‘æ§<br/>100ms]
    end

    subgraph "Phoenix å•ç‹¬"
        P[Phoenix<br/>101-102ms<br/>+1-2%]
    end

    subgraph "Langfuse å•ç‹¬"
        L[Langfuse<br/>102-103ms<br/>+2-3%]
    end

    subgraph "ä¸¤è€…åŒæ—¶"
        Both[Both<br/>103-105ms<br/>+3-5%]
    end

    subgraph "é‡‡æ ·å"
        Sample[é‡‡æ · 10%<br/>101-102ms<br/>+1-2%]
    end

    Base -.->|å¯ç”¨| P
    Base -.->|å¯ç”¨| L
    Base -.->|å¯ç”¨| Both
    Both -.->|é‡‡æ ·| Sample

    style Base fill:#d4edda
    style Both fill:#f8d7da
    style Sample fill:#d4edda
```

## æŠ€æœ¯å®ç°å¯¹æ¯”

### ä»£ç†æ¨¡å¼è¯¦è§£

```mermaid
graph TB
    subgraph "Langfuse: æ˜¾å¼ä»£ç†"
        LF1[åŸå§‹å®¢æˆ·ç«¯] -->|åŒ…è£…| LF2[LangfuseOpenAI]
        LF2 -->|ç»§æ‰¿/ç»„åˆ| LF3[æ‹¦æˆªæ‰€æœ‰æ–¹æ³•]
        LF3 -->|"chat.completions.create()"| LF4[è®°å½• â†’ è°ƒç”¨ â†’ è®°å½•]
    end

    subgraph "Phoenix: è¿è¡Œæ—¶æ³¨å…¥"
        PH1[OpenAI ç±»] -->|instrument| PH2[Monkey Patch]
        PH2 -->|æ›¿æ¢æ–¹æ³•| PH3[æ³¨å…¥ Hook]
        PH3 -->|"chat.completions.create()"| PH4[Hook â†’ åŸå§‹ â†’ Hook]
    end

    style LF2 fill:#ffe1f5
    style PH2 fill:#e1f5ff
```

### ä»£ç å±‚é¢å¯¹æ¯”

**Langfuse ä½¿ç”¨ï¼ˆæ˜¾å¼ï¼‰**ï¼š
```python
# 1. åˆ›å»ºåŸå§‹å®¢æˆ·ç«¯
from openai import OpenAI
client = OpenAI(api_key="...")

# 2. æ˜¾å¼åŒ…è£…ï¼ˆåŠ ç½‘å…³ï¼‰
from langfuse.openai import OpenAI as LangfuseOpenAI
client = LangfuseOpenAI(api_key="...")  # æ›¿æ¢ä¸ºä»£ç†å®¢æˆ·ç«¯

# 3. æ­£å¸¸ä½¿ç”¨ï¼ˆæµé‡ç»è¿‡ç½‘å…³ï¼‰
response = client.chat.completions.create(...)
# â†‘ è¿™ä¸ªè°ƒç”¨ä¼šè¢« Langfuse æ‹¦æˆªã€è®°å½•ã€è½¬å‘
```

**Phoenix ä½¿ç”¨ï¼ˆéšå¼ï¼‰**ï¼š
```python
# 1. æ³¨å†Œ Phoenixï¼ˆè‡ªåŠ¨æ³¨å…¥ç½‘å…³ï¼‰
from phoenix.otel import register
register()

# 2. è‡ªåŠ¨æ³¨å…¥è¿½è¸ªï¼ˆè¿è¡Œæ—¶ä¿®æ”¹ OpenAI ç±»ï¼‰
from openinference.instrumentation.openai import OpenAIInstrumentor
OpenAIInstrumentor().instrument()

# 3. æ­£å¸¸ä½¿ç”¨ï¼ˆæµé‡è‡ªåŠ¨ç»è¿‡ç½‘å…³ï¼‰
from openai import OpenAI
client = OpenAI(api_key="...")
response = client.chat.completions.create(...)
# â†‘ è¿™ä¸ªè°ƒç”¨ä¼šè¢«è‡ªåŠ¨è¿½è¸ªï¼Œæ— éœ€ä¿®æ”¹ä»£ç 
```

### ç½‘å…³å±‚åšäº†ä»€ä¹ˆï¼Ÿ

```mermaid
sequenceDiagram
    participant App as åº”ç”¨ä»£ç 
    participant Gateway as ç½‘å…³å±‚
    participant Monitor as ç›‘æ§ç³»ç»Ÿ
    participant LLM as LLM API

    App->>Gateway: 1. å‘èµ·è°ƒç”¨
    activate Gateway

    Gateway->>Monitor: 2. è®°å½•è¯·æ±‚å¼€å§‹
    Note over Monitor: - æ—¶é—´æˆ³<br/>- è¯·æ±‚å‚æ•°<br/>- æ¨¡å‹åç§°

    Gateway->>LLM: 3. è½¬å‘è¯·æ±‚
    activate LLM
    LLM-->>Gateway: 4. è¿”å›å“åº”
    deactivate LLM

    Gateway->>Monitor: 5. è®°å½•å“åº”ç»“æŸ
    Note over Monitor: - å“åº”å†…å®¹<br/>- Token ç”¨é‡<br/>- å»¶è¿Ÿæ—¶é—´<br/>- è®¡ç®—æˆæœ¬

    Gateway-->>App: 6. è¿”å›ç»“æœ
    deactivate Gateway
```

### ä¸ºä»€ä¹ˆéœ€è¦ä¸¤å±‚ç½‘å…³ï¼Ÿ

```mermaid
graph LR
    App[åº”ç”¨] -->|è°ƒç”¨| L[Langfuse ç½‘å…³]
    L -->|è½¬å‘| P[Phoenix ç½‘å…³]
    P -->|è°ƒç”¨| LLM[LLM API]

    L -.->|è®°å½•| LDB[(Langfuse DB<br/>ä¸šåŠ¡æ•°æ®)]
    P -.->|è®°å½•| PDB[(Phoenix DB<br/>æŠ€æœ¯æ•°æ®)]

    style L fill:#ffe1f5
    style P fill:#e1f5ff
```

**åŸå› **ï¼š
- **Langfuse**: æ˜¾å¼åŒ…è£…åœ¨æœ€å¤–å±‚ï¼Œè®°å½•ä¸šåŠ¡æŒ‡æ ‡
- **Phoenix**: è¿è¡Œæ—¶æ³¨å…¥åœ¨å†…å±‚ï¼Œè‡ªåŠ¨è®°å½•æŠ€æœ¯æŒ‡æ ‡
- **ä¸å†²çª**: Phoenix æ‹¦æˆªçš„æ˜¯å·²ç»è¢« Langfuse åŒ…è£…åçš„è°ƒç”¨
- **æ•°æ®ç‹¬ç«‹**: ä¸¤ä¸ªç³»ç»Ÿå„è‡ªè®°å½•ï¼Œäº’ä¸å½±å“

### æ€§èƒ½å¼€é”€æ¥æº

```mermaid
graph TB
    Call[åŸå§‹è°ƒç”¨ 100ms]
    Call -->|Langfuse| L1[+è®°å½•è¯·æ±‚ 1ms]
    L1 --> L2[+åºåˆ—åŒ–æ•°æ® 1ms]
    L2 --> L3[+é˜Ÿåˆ—å…¥é˜Ÿ <1ms]

    Call -->|Phoenix| P1[+åˆ›å»º Span 1ms]
    P1 --> P2[+è®°å½•å±æ€§ 1ms]
    P2 --> P3[+å¯¼å‡ºæ•°æ® <1ms]

    L3 --> Total[æ€»è®¡: 103-105ms]
    P3 --> Total

    style Call fill:#d4edda
    style Total fill:#fff4e1
```

## LLM æ”¯æŒèŒƒå›´

### Phoenix æ”¯æŒçš„ LLMï¼ˆå‡ ä¹å…¨è¦†ç›–ï¼‰

```mermaid
graph TB
    subgraph "ç›´æ¥ SDK æ”¯æŒ"
        OpenAI[OpenAI SDK<br/>GPT-3.5/4/4o]
        Anthropic[Anthropic SDK<br/>Claude Series]
        Bedrock[AWS Bedrock<br/>Claude/Mistral/Llama]
        VertexAI[Google VertexAI<br/>Gemini/PaLM]
        Mistral[MistralAI SDK<br/>Mistral Models]
        LiteLLM[LiteLLM<br/>100+ Providers]
    end

    subgraph "æ¡†æ¶æ”¯æŒ"
        LangChain[LangChain<br/>æ‰€æœ‰é›†æˆ]
        LlamaIndex[LlamaIndex<br/>æ‰€æœ‰é›†æˆ]
        Haystack[Haystack]
        DSPy[DSPy]
    end

    subgraph "OpenAI å…¼å®¹ API"
        DeepSeek[DeepSeek æ·±åº¦æ±‚ç´¢]
        Qwen[Qwen é€šä¹‰åƒé—®]
        GLM[GLM æ™ºè°±]
        Moonshot[Moonshot æœˆä¹‹æš—é¢]
        Custom[ä»»ä½• OpenAI å…¼å®¹æœåŠ¡]
    end

    Phoenix[Phoenix è¿½è¸ªå™¨] -.->|instrument| OpenAI
    Phoenix -.->|instrument| Anthropic
    Phoenix -.->|instrument| Bedrock
    Phoenix -.->|instrument| VertexAI
    Phoenix -.->|instrument| Mistral
    Phoenix -.->|instrument| LiteLLM

    Phoenix -.->|instrument| LangChain
    Phoenix -.->|instrument| LlamaIndex
    Phoenix -.->|instrument| Haystack
    Phoenix -.->|instrument| DSPy

    OpenAI -.->|å…¼å®¹| DeepSeek
    OpenAI -.->|å…¼å®¹| Qwen
    OpenAI -.->|å…¼å®¹| GLM
    OpenAI -.->|å…¼å®¹| Moonshot
    OpenAI -.->|å…¼å®¹| Custom

    style Phoenix fill:#d4edda
    style OpenAI fill:#e1f5ff
    style LiteLLM fill:#fff4e1
```

### å½“å‰é¡¹ç›®é…ç½®

```python
# é¡¹ç›®ä½¿ç”¨ OpenAI SDK + DeepSeek åç«¯
from openai import OpenAI

client = OpenAI(
    base_url="https://space.ai-builders.com/backend/v1",  # DeepSeek API
    api_key="...",
)

# Phoenix çš„ OpenAIInstrumentor å¯ä»¥è¿½è¸ªï¼
# å› ä¸ºè¿½è¸ªçš„æ˜¯å®¢æˆ·ç«¯è°ƒç”¨ï¼Œä¸æ˜¯åç«¯æœåŠ¡
```

### å®‰è£…ä¸åŒ LLM çš„ Instrumentor

```bash
# OpenAI (å·²å®‰è£…)
pip install openinference-instrumentation-openai

# Anthropic Claude
pip install openinference-instrumentation-anthropic

# AWS Bedrock (æ”¯æŒ Claude, Mistral, Llama ç­‰)
pip install openinference-instrumentation-bedrock

# MistralAI
pip install openinference-instrumentation-mistralai

# LiteLLM (ä¸€æ¬¡æ€§æ”¯æŒ 100+ LLM)
pip install openinference-instrumentation-litellm

# LangChain
pip install openinference-instrumentation-langchain

# LlamaIndex
pip install openinference-instrumentation-llama-index
```

### ä½¿ç”¨ç¤ºä¾‹

#### æ–¹å¼ 1: OpenAI å…¼å®¹ APIï¼ˆå½“å‰é¡¹ç›®ï¼‰

```python
from openai import OpenAI

# ä»»ä½• OpenAI å…¼å®¹çš„æœåŠ¡éƒ½å¯ä»¥è¢«è¿½è¸ª
providers = {
    "deepseek": "https://api.deepseek.com/v1",
    "moonshot": "https://api.moonshot.cn/v1",
    "qwen": "https://dashscope.aliyuncs.com/compatible-mode/v1",
    "glm": "https://open.bigmodel.cn/api/paas/v4",
}

client = OpenAI(
    base_url=providers["deepseek"],
    api_key="..."
)

# Phoenix è‡ªåŠ¨è¿½è¸ª âœ…
response = client.chat.completions.create(...)
```

#### æ–¹å¼ 2: ç›´æ¥ä½¿ç”¨åŸç”Ÿ SDK

```python
# Anthropic Claude
from anthropic import Anthropic

# éœ€è¦å¯ç”¨: phoenix_tracer.instrument_anthropic()
client = Anthropic(api_key="...")
response = client.messages.create(...)  # è‡ªåŠ¨è¿½è¸ª âœ…

# AWS Bedrock
import boto3

# éœ€è¦å¯ç”¨: phoenix_tracer.instrument_bedrock()
bedrock = boto3.client('bedrock-runtime')
response = bedrock.invoke_model(...)  # è‡ªåŠ¨è¿½è¸ª âœ…
```

#### æ–¹å¼ 3: ä½¿ç”¨ LiteLLMï¼ˆæ¨èå¤š LLM åœºæ™¯ï¼‰

```python
from litellm import completion

# éœ€è¦å¯ç”¨: phoenix_tracer.instrument_litellm()

# æ”¯æŒ 100+ LLMï¼Œç»Ÿä¸€æ¥å£
response = completion(
    model="gpt-4",           # OpenAI
    messages=[...]
)

response = completion(
    model="claude-3-opus",   # Anthropic
    messages=[...]
)

response = completion(
    model="deepseek/deepseek-chat",  # DeepSeek
    messages=[...]
)

# å…¨éƒ¨è‡ªåŠ¨è¿½è¸ª âœ…
```

### å…¼å®¹æ€§çŸ©é˜µ

| LLM æä¾›å•† | è¿½è¸ªæ–¹å¼ | éœ€è¦å®‰è£… | é¡¹ç›®æ”¯æŒ |
|-----------|---------|---------|---------|
| OpenAI | OpenAIInstrumentor | `openinference-instrumentation-openai` | âœ… å·²å¯ç”¨ |
| DeepSeek | OpenAIInstrumentor | æ— éœ€é¢å¤–å®‰è£…ï¼ˆå…¼å®¹ OpenAIï¼‰ | âœ… å·²æ”¯æŒ |
| Anthropic | AnthropicInstrumentor | `openinference-instrumentation-anthropic` | ğŸ“ å·²æ·»åŠ æ–¹æ³• |
| AWS Bedrock | BedrockInstrumentor | `openinference-instrumentation-bedrock` | ğŸ“ å·²æ·»åŠ æ–¹æ³• |
| MistralAI | MistralInstrumentor | `openinference-instrumentation-mistralai` | ğŸ“ å·²æ·»åŠ æ–¹æ³• |
| LiteLLM | LiteLLMInstrumentor | `openinference-instrumentation-litellm` | ğŸ“ å·²æ·»åŠ æ–¹æ³• |
| é€šä¹‰åƒé—® | OpenAIInstrumentor | æ— éœ€é¢å¤–å®‰è£…ï¼ˆå…¼å®¹ OpenAIï¼‰ | âœ… å¯ç›´æ¥ç”¨ |
| æ™ºè°± GLM | OpenAIInstrumentor | æ— éœ€é¢å¤–å®‰è£…ï¼ˆå…¼å®¹ OpenAIï¼‰ | âœ… å¯ç›´æ¥ç”¨ |
| æœˆä¹‹æš—é¢ | OpenAIInstrumentor | æ— éœ€é¢å¤–å®‰è£…ï¼ˆå…¼å®¹ OpenAIï¼‰ | âœ… å¯ç›´æ¥ç”¨ |

### Langfuse æ”¯æŒçš„ LLM

Langfuse é€šè¿‡ wrapper æ¨¡å¼ï¼Œç†è®ºä¸Šæ”¯æŒæ‰€æœ‰ LLMï¼š

```python
# OpenAI åŠå…¼å®¹æœåŠ¡
from langfuse.openai import OpenAI
client = OpenAI(base_url="...", api_key="...")

# Anthropic
from langfuse.anthropic import Anthropic
client = Anthropic(api_key="...")

# LiteLLM
from langfuse.litellm import litellm_wrapper
completion = litellm_wrapper(completion)
```

ä½† Langfuse ç›®å‰ä¸»è¦ä¼˜åŒ–äº† OpenAI çš„è¿½è¸ªï¼Œå…¶ä»– LLM å¯èƒ½éœ€è¦æ‰‹åŠ¨é…ç½®ã€‚

### æ¨èæ–¹æ¡ˆ

```mermaid
graph TB
    Start{ä½¿ç”¨åœºæ™¯}

    Start -->|å•ä¸€ LLM| Direct[ç›´æ¥ä½¿ç”¨åŸç”Ÿ SDK]
    Start -->|OpenAI å…¼å®¹| OpenAISDK[ä½¿ç”¨ OpenAI SDK]
    Start -->|å¤š LLM åˆ‡æ¢| LiteLLM[ä½¿ç”¨ LiteLLM]
    Start -->|æ¡†æ¶| Framework[LangChain/LlamaIndex]

    Direct -->|Phoenix| Phoenix1[å¯¹åº” Instrumentor]
    OpenAISDK -->|Phoenix| Phoenix2[OpenAI Instrumentor]
    LiteLLM -->|Phoenix| Phoenix3[LiteLLM Instrumentor]
    Framework -->|Phoenix| Phoenix4[Framework Instrumentor]

    Direct -->|Langfuse| LF1[åŸç”Ÿ Wrapper]
    OpenAISDK -->|Langfuse| LF2[OpenAI Wrapper âœ…]
    LiteLLM -->|Langfuse| LF3[LiteLLM Wrapper]
    Framework -->|Langfuse| LF4[æ‰‹åŠ¨è¿½è¸ª]

    style OpenAISDK fill:#d4edda
    style LiteLLM fill:#fff4e1
    style Phoenix2 fill:#e1f5ff
```

## æ€»ç»“

### Phoenix ç‰¹ç‚¹
- âœ… åŸºäº OpenTelemetry å¼€æ”¾æ ‡å‡†
- âœ… **AOP åˆ‡é¢æ¨¡å¼**ï¼Œè‡ªåŠ¨æ³¨å…¥ï¼Œé›¶ä»£ç ä¿®æ”¹
- âœ… æœ¬åœ°éƒ¨ç½²ï¼Œå®Œå…¨å…è´¹
- âœ… å®éªŒå’Œè¯„ä¼°åŠŸèƒ½å¼ºå¤§
- âœ… Session çº§åˆ«è¿½è¸ª
- âš ï¸ ä¸»è¦ç”¨äºå¼€å‘é˜¶æ®µ

### Langfuse ç‰¹ç‚¹
- âœ… **ä»£ç†æ¨¡å¼**ï¼Œæ˜¾å¼åŒ…è£…
- âœ… äº‘ç«¯/è‡ªæ‰˜ç®¡ï¼Œæ•°æ®æŒä¹…åŒ–
- âœ… æˆæœ¬åˆ†æå’Œä¸šåŠ¡æŒ‡æ ‡
- âœ… ç”Ÿäº§ç›‘æ§åŠŸèƒ½å®Œå–„
- âš ï¸ éœ€è¦é¢å¤–é…ç½®

### ç½‘å…³æ¨¡å¼ä¼˜åŠ¿
- âœ… **æ— ä¾µå…¥**ï¼šä¸šåŠ¡ä»£ç æ— éœ€ä¿®æ”¹ï¼ˆæˆ–æœ€å°ä¿®æ”¹ï¼‰
- âœ… **å¯æ’æ‹”**ï¼šå¯ä»¥éšæ—¶å¯ç”¨/ç¦ç”¨
- âœ… **é€æ˜åŒ–**ï¼šå¯¹ LLM è°ƒç”¨å…¨é¢å¯è§
- âœ… **æ ‡å‡†åŒ–**ï¼šåŸºäºæˆç†Ÿçš„è®¾è®¡æ¨¡å¼

### æ¨èç­–ç•¥
1. **å¼€å‘**: åªç”¨ Phoenix (AOP è‡ªåŠ¨è¿½è¸ªï¼Œæ–¹ä¾¿å®éªŒ)
2. **æµ‹è¯•**: ä¸¤è€…éƒ½å¯ç”¨ (å…¨é¢ç›‘æ§)
3. **ç”Ÿäº§**: ä¸»ç”¨ Langfuse (æ˜¾å¼æ§åˆ¶ï¼Œä¸šåŠ¡ç›‘æ§)
4. **è¯Šæ–­**: å›åˆ° Phoenix (å¼ºå¤§çš„è°ƒè¯•åŠŸèƒ½)

---

**åˆ›å»ºæ—¥æœŸ**: 2026-01-31
**ç»´æŠ¤è€…**: Sheldon
**ç‰ˆæœ¬**: 1.0.0

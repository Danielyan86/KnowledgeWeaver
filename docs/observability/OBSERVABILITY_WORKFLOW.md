# Phoenix + Langfuse é…åˆä½¿ç”¨å·¥ä½œæµ

## æ ¸å¿ƒç†å¿µ

- **Phoenix**ï¼šå¼€å‘é˜¶æ®µçš„å®éªŒå®¤ ğŸ§ª
- **Langfuse**ï¼šç”Ÿäº§é˜¶æ®µçš„ç›‘æ§å° ğŸ“Š
- **äº’ä¸å†²çª**ï¼šå¯ä»¥åŒæ—¶å¯ç”¨ï¼Œæ•°æ®ç‹¬ç«‹

## å®Œæ•´å·¥ä½œæµ

### é˜¶æ®µ 1ï¼šå¼€å‘å’Œä¼˜åŒ–ï¼ˆä½¿ç”¨ Phoenixï¼‰

```bash
# é…ç½®
PHOENIX_ENABLED=true
LANGFUSE_ENABLED=false  # å¼€å‘é˜¶æ®µå¯ä»¥ä¸å¯ç”¨
```

**æ­¥éª¤ 1ï¼šPrompt å¼€å‘**
1. å†™ä¸€ä¸ªåˆç‰ˆ Prompt
2. åœ¨ä»£ç ä¸­è°ƒç”¨ LLM
3. Phoenix è‡ªåŠ¨è¿½è¸ªæ‰€æœ‰è°ƒç”¨
4. åœ¨ http://localhost:6006 æŸ¥çœ‹ç»“æœ

**æ­¥éª¤ 2ï¼šPrompt ä¼˜åŒ–**
1. åœ¨ Phoenix UI é€‰æ‹©ä¸€ä¸ªè¿½è¸ªè®°å½•
2. ç‚¹å‡» "Open in Playground"
3. ä¿®æ”¹ Promptï¼Œå®æ—¶å¯¹æ¯”è¾“å‡º
4. æµ‹è¯•ä¸åŒçš„æ¨¡å‹ï¼ˆGPT-3.5 vs GPT-4ï¼‰
5. è°ƒæ•´å‚æ•°ï¼ˆtemperature, max_tokensï¼‰
6. æ‰¾åˆ°æœ€ä½³ç»„åˆ

**æ­¥éª¤ 3ï¼šè¯„ä¼°éªŒè¯**
```python
from phoenix.evals import (
    llm_classify,
    OpenAIModel,
    run_evals
)

# å‡†å¤‡æµ‹è¯•æ•°æ®é›†
test_cases = [
    {"input": "é—®é¢˜1", "expected": "ç­”æ¡ˆ1"},
    {"input": "é—®é¢˜2", "expected": "ç­”æ¡ˆ2"},
    # ... 50ä¸ªæµ‹è¯•ç”¨ä¾‹
]

# è¯„ä¼° Prompt è´¨é‡
eval_model = OpenAIModel(model="gpt-4", temperature=0)

# è¯„ä¼°å‡†ç¡®æ€§
accuracy = llm_classify(
    dataframe=test_cases,
    model=eval_model,
    template="Is this answer correct? Answer YES or NO.",
    rails=["YES", "NO"]
)

# è¯„ä¼°ç›¸å…³æ€§
relevance = llm_classify(
    dataframe=test_cases,
    model=eval_model,
    template="Is this answer relevant? Answer YES or NO.",
    rails=["YES", "NO"]
)

print(f"å‡†ç¡®ç‡: {accuracy.score()}")
print(f"ç›¸å…³æ€§: {relevance.score()}")
```

**æ­¥éª¤ 4ï¼šA/B æµ‹è¯•**
```python
from phoenix.experiments import run_experiment

# å¯¹æ¯”ä¸¤ä¸ªç‰ˆæœ¬
experiment_results = run_experiment(
    dataset=test_cases,
    task=your_qa_function,
    experiment_name="prompt-v2-vs-v3",
    evaluators=[accuracy_evaluator, relevance_evaluator]
)

# æŸ¥çœ‹å¯¹æ¯”ç»“æœ
print(experiment_results.summary())
# Prompt v2: å‡†ç¡®ç‡ 85%, ç›¸å…³æ€§ 90%
# Prompt v3: å‡†ç¡®ç‡ 92%, ç›¸å…³æ€§ 88%
# â†’ é€‰æ‹© v3ï¼ˆå‡†ç¡®æ€§æ›´é‡è¦ï¼‰
```

---

### é˜¶æ®µ 2ï¼šæµ‹è¯•ç¯å¢ƒï¼ˆåŒæ—¶å¯ç”¨ï¼‰

```bash
# é…ç½®
PHOENIX_ENABLED=true   # ç»§ç»­ä¼˜åŒ–
LANGFUSE_ENABLED=true  # å¼€å§‹æ”¶é›†ç”Ÿäº§æ•°æ®
```

**ç›®æ ‡ï¼š**
- Phoenixï¼šç»§ç»­ç›‘æ§æ€§èƒ½ï¼Œå‘ç°é—®é¢˜
- Langfuseï¼šæ”¶é›†çœŸå®æ•°æ®ï¼Œå‡†å¤‡ä¸Šçº¿

**æ“ä½œï¼š**
```python
# ä¸¤ä¸ªè¿½è¸ªå™¨åŒæ—¶åˆå§‹åŒ–
from backend.core.phoenix_observability import get_phoenix_tracer
from backend.core.observability import get_tracer as get_langfuse_tracer

phoenix_tracer = get_phoenix_tracer()    # è‡ªåŠ¨è¿½è¸ª
langfuse_tracer = get_langfuse_tracer()  # æ‰‹åŠ¨åŒ…è£…

# OpenAI å®¢æˆ·ç«¯
client = OpenAI(api_key=api_key)

# Langfuse wrapper
if langfuse_tracer.enabled:
    client = langfuse_tracer.wrap_openai(client)

# ä½¿ç”¨å®¢æˆ·ç«¯ï¼ˆä¸¤ä¸ªç³»ç»Ÿéƒ½ä¼šè®°å½•ï¼‰
response = client.chat.completions.create(
    model="gpt-4",
    messages=[{"role": "user", "content": query}]
)

# Phoenixï¼šæŸ¥çœ‹æŠ€æœ¯æŒ‡æ ‡ï¼ˆå»¶è¿Ÿã€Tokenï¼‰
# Langfuseï¼šæŸ¥çœ‹ä¸šåŠ¡æŒ‡æ ‡ï¼ˆæˆæœ¬ã€ç”¨æˆ·è¡Œä¸ºï¼‰
```

---

### é˜¶æ®µ 3ï¼šç”Ÿäº§ç¯å¢ƒï¼ˆä½¿ç”¨ Langfuseï¼‰

```bash
# é…ç½®
PHOENIX_ENABLED=false   # å…³é—­æˆ–é‡‡æ ·
LANGFUSE_ENABLED=true   # ä¸»è¦ç›‘æ§å·¥å…·
```

**ä¸ºä»€ä¹ˆåˆ‡æ¢ï¼Ÿ**
- ç”Ÿäº§ç¯å¢ƒé‡ç‚¹æ˜¯ç›‘æ§å’Œåˆ†æï¼Œä¸éœ€è¦å®éªŒåŠŸèƒ½
- Langfuse çš„åˆ†æåŠŸèƒ½æ›´å¼ºå¤§
- é™ä½ç³»ç»Ÿå¼€é”€

**å¯é€‰ï¼šä¿ç•™ Phoenix é‡‡æ ·è¿½è¸ª**
```bash
PHOENIX_ENABLED=true
PHOENIX_SAMPLING_RATE=0.1  # åªè¿½è¸ª 10% çš„è¯·æ±‚
LANGFUSE_ENABLED=true
```

**Langfuse ç›‘æ§å†…å®¹ï¼š**
1. **æˆæœ¬è¿½è¸ª**
   - æ¯æ—¥æˆæœ¬è¶‹åŠ¿
   - æŒ‰ç”¨æˆ·/åŠŸèƒ½åˆ†ç»„çš„æˆæœ¬
   - é¢„è­¦ï¼šæˆæœ¬è¶…è¿‡é¢„ç®—

2. **æ€§èƒ½ç›‘æ§**
   - å¹³å‡å“åº”æ—¶é—´
   - æ…¢æŸ¥è¯¢åˆ†æ
   - é”™è¯¯ç‡è¿½è¸ª

3. **ç”¨æˆ·åˆ†æ**
   - å“ªäº›ç”¨æˆ·ä½¿ç”¨æœ€é¢‘ç¹ï¼Ÿ
   - å“ªäº›é—®é¢˜è¢«é—®å¾—æœ€å¤šï¼Ÿ
   - ç”¨æˆ·æ»¡æ„åº¦å¦‚ä½•ï¼Ÿ

4. **è´¨é‡ç›‘æ§**
   - Token ä½¿ç”¨æ˜¯å¦åˆç†ï¼Ÿ
   - æ˜¯å¦æœ‰å¼‚å¸¸è°ƒç”¨ï¼Ÿ
   - è¾“å‡ºè´¨é‡æ˜¯å¦ç¨³å®šï¼Ÿ

---

### é˜¶æ®µ 4ï¼šæŒç»­ä¼˜åŒ–ï¼ˆå›åˆ° Phoenixï¼‰

**è§¦å‘æ¡ä»¶ï¼š**
- Langfuse å‘ç°é—®é¢˜ï¼ˆä¾‹å¦‚ï¼šæˆæœ¬è¿‡é«˜ã€å“åº”æ…¢ï¼‰
- æ”¶åˆ°ç”¨æˆ·åé¦ˆï¼ˆä¾‹å¦‚ï¼šç­”æ¡ˆè´¨é‡ä¸‹é™ï¼‰
- éœ€è¦æ·»åŠ æ–°åŠŸèƒ½

**æµç¨‹ï¼š**
```bash
# 1. ä» Langfuse å¯¼å‡ºé—®é¢˜æ•°æ®
curl -X GET "https://cloud.langfuse.com/api/traces?filter=slow" \
  -H "Authorization: Bearer $LANGFUSE_API_KEY" \
  > slow_traces.json

# 2. åœ¨å¼€å‘ç¯å¢ƒé‡ç°é—®é¢˜
PHOENIX_ENABLED=true
LANGFUSE_ENABLED=false

# 3. ä½¿ç”¨ Phoenix è¯Šæ–­
# - Playground ä¸­é‡æ”¾æ…¢æŸ¥è¯¢
# - åˆ†æä¸ºä»€ä¹ˆæ…¢ï¼ˆToken å¤ªå¤šï¼Ÿæ¨¡å‹é€‰æ‹©ï¼Ÿï¼‰
# - ä¼˜åŒ– Prompt

# 4. è¯„ä¼°æ”¹è¿›æ•ˆæœ
python evaluate_optimization.py

# 5. éƒ¨ç½²åˆ°ç”Ÿäº§
# 6. åœ¨ Langfuse éªŒè¯æ”¹è¿›ï¼ˆæˆæœ¬é™ä½äº†å—ï¼Ÿé€Ÿåº¦æå‡äº†å—ï¼Ÿï¼‰
```

---

## å…·ä½“ä½¿ç”¨åœºæ™¯

### åœºæ™¯ 1ï¼šå¼€å‘æ–°åŠŸèƒ½

**éœ€æ±‚**ï¼šæ·»åŠ "æ–‡æ¡£æ‘˜è¦"åŠŸèƒ½

**ä½¿ç”¨ Phoenix**ï¼š
```python
# 1. å¼€å‘åˆç‰ˆ
def summarize_document(doc_text):
    response = client.chat.completions.create(
        model="gpt-3.5-turbo",
        messages=[{
            "role": "user",
            "content": f"è¯·æ€»ç»“è¿™æ®µæ–‡å­—ï¼š\n{doc_text}"
        }]
    )
    return response.choices[0].message.content

# 2. åœ¨ Phoenix Playground æµ‹è¯•
# - è°ƒæ•´ Prompt
# - å¯¹æ¯” gpt-3.5-turbo vs gpt-4
# - æµ‹è¯•ä¸åŒé•¿åº¦çš„æ–‡æ¡£

# 3. è¯„ä¼°è´¨é‡
test_docs = load_test_documents()
results = evaluate_summaries(test_docs)
# å‡†ç¡®ç‡: 75%ï¼ˆä¸å¤Ÿå¥½ï¼‰

# 4. ä¼˜åŒ– Prompt
def summarize_document_v2(doc_text):
    response = client.chat.completions.create(
        model="gpt-4",
        messages=[{
            "role": "system",
            "content": "ä½ æ˜¯æ–‡æ¡£æ‘˜è¦ä¸“å®¶ï¼Œæ“…é•¿æç‚¼æ ¸å¿ƒè§‚ç‚¹ã€‚"
        }, {
            "role": "user",
            "content": f"è¯·ç”¨3-5å¥è¯æ€»ç»“è¿™æ®µæ–‡å­—çš„æ ¸å¿ƒè§‚ç‚¹ï¼š\n{doc_text}"
        }]
    )
    return response.choices[0].message.content

# 5. å†æ¬¡è¯„ä¼°
results = evaluate_summaries(test_docs)
# å‡†ç¡®ç‡: 92%ï¼ˆè¾¾æ ‡ï¼ï¼‰
```

**ä¸Šçº¿åï¼Œä½¿ç”¨ Langfuse**ï¼š
- ç›‘æ§å®é™…ä½¿ç”¨æƒ…å†µ
- æˆæœ¬ï¼šæ¯æ¬¡æ‘˜è¦ $0.05
- æ€§èƒ½ï¼šå¹³å‡ 3 ç§’
- ç”¨æˆ·åé¦ˆï¼š90% æ»¡æ„

---

### åœºæ™¯ 2ï¼šä¼˜åŒ–æˆæœ¬

**é—®é¢˜**ï¼šLangfuse æ˜¾ç¤ºæˆæœ¬è¿‡é«˜

**Langfuse åˆ†æ**ï¼š
```
æœˆåº¦æŠ¥å‘Šï¼š
- æ€»æˆæœ¬: $500
- ä¸»è¦èŠ±è´¹: QA åŠŸèƒ½ï¼ˆ$400, 80%ï¼‰
- å¹³å‡æ¯æ¬¡è°ƒç”¨: $0.10
- åŸå› : ä½¿ç”¨ GPT-4 + é•¿ä¸Šä¸‹æ–‡
```

**ä½¿ç”¨ Phoenix ä¼˜åŒ–**ï¼š
```python
# 1. åœ¨ Phoenix ä¸­é‡ç°åœºæ™¯
# 2. æµ‹è¯•æ–¹æ¡ˆ A: ç¼©çŸ­ä¸Šä¸‹æ–‡
def qa_optimized_v1(query, context):
    # åªä¿ç•™æœ€ç›¸å…³çš„ top-3 æ®µè½
    context = filter_top_k(context, k=3)
    response = client.chat.completions.create(
        model="gpt-4",
        messages=[...]
    )
    return response

# 3. æµ‹è¯•æ–¹æ¡ˆ B: ä½¿ç”¨ GPT-3.5
def qa_optimized_v2(query, context):
    response = client.chat.completions.create(
        model="gpt-3.5-turbo",  # ä¾¿å®œ 10 å€
        messages=[...]
    )
    return response

# 4. A/B æµ‹è¯•
experiment = run_experiment(
    dataset=test_cases,
    tasks=[qa_optimized_v1, qa_optimized_v2],
    evaluators=[accuracy, relevance, cost]
)

# ç»“æœï¼š
# æ–¹æ¡ˆ A (GPT-4 + çŸ­ä¸Šä¸‹æ–‡): å‡†ç¡®ç‡ 88%, æˆæœ¬ $0.05
# æ–¹æ¡ˆ B (GPT-3.5 + é•¿ä¸Šä¸‹æ–‡): å‡†ç¡®ç‡ 82%, æˆæœ¬ $0.01
# â†’ é€‰æ‹©æ–¹æ¡ˆ Aï¼ˆå¹³è¡¡è´¨é‡å’Œæˆæœ¬ï¼‰
```

**éƒ¨ç½²åï¼ŒLangfuse éªŒè¯**ï¼š
```
ä¸‹æœˆæŠ¥å‘Šï¼š
- æ€»æˆæœ¬: $250ï¼ˆé™ä½ 50%ï¼ï¼‰
- QA åŠŸèƒ½: $200
- å¹³å‡æ¯æ¬¡è°ƒç”¨: $0.05
- è´¨é‡: å‡†ç¡®ç‡ç»´æŒåœ¨ 88%
```

---

### åœºæ™¯ 3ï¼šè¯Šæ–­é—®é¢˜

**é—®é¢˜**ï¼šç”¨æˆ·åé¦ˆç­”æ¡ˆè´¨é‡ä¸‹é™

**Langfuse åˆ†æ**ï¼š
- é”™è¯¯ç‡ä» 0.5% ä¸Šå‡åˆ° 5%
- é—®é¢˜é›†ä¸­åœ¨æŸç±»é—®é¢˜ä¸Š
- å¯¼å‡ºé—®é¢˜æ•°æ®

**ä½¿ç”¨ Phoenix è¯Šæ–­**ï¼š
```python
# 1. åŠ è½½é—®é¢˜æ•°æ®
problem_cases = load_from_langfuse("error_traces.json")

# 2. åœ¨ Phoenix ä¸­é‡æ”¾
for case in problem_cases:
    response = qa_function(case["query"])
    # Phoenix è‡ªåŠ¨è®°å½•

# 3. åœ¨ Playground åˆ†æ
# - å‘ç°ï¼šæŸäº›é—®é¢˜çš„ä¸Šä¸‹æ–‡æ£€ç´¢å¤±è´¥
# - åŸå› ï¼šå‘é‡æ•°æ®åº“æ›´æ–°åç´¢å¼•æŸå

# 4. ä¿®å¤å¹¶éªŒè¯
fix_vector_index()
test_results = evaluate_fixed_system(problem_cases)
# é”™è¯¯ç‡é™åˆ° 0.8%

# 5. éƒ¨ç½²ä¿®å¤
```

---

## é…ç½®ç¤ºä¾‹

### å¼€å‘ç¯å¢ƒï¼ˆ`dev.env`ï¼‰

```bash
# Phoenix - å®éªŒå’Œä¼˜åŒ–
PHOENIX_ENABLED=true
PHOENIX_COLLECTOR_ENDPOINT=http://localhost:4317
PHOENIX_PROJECT_NAME=knowledge-weaver-dev

# Langfuse - å¯é€‰
LANGFUSE_ENABLED=false
```

### æµ‹è¯•ç¯å¢ƒï¼ˆ`test.env`ï¼‰

```bash
# Phoenix - ç»§ç»­ç›‘æ§
PHOENIX_ENABLED=true
PHOENIX_COLLECTOR_ENDPOINT=http://test-phoenix:4317
PHOENIX_PROJECT_NAME=knowledge-weaver-test

# Langfuse - å¼€å§‹æ”¶é›†æ•°æ®
LANGFUSE_ENABLED=true
LANGFUSE_HOST=http://test-langfuse:3000
```

### ç”Ÿäº§ç¯å¢ƒï¼ˆ`prod.env`ï¼‰

```bash
# Phoenix - é‡‡æ ·è¿½è¸ªï¼ˆå¯é€‰ï¼‰
PHOENIX_ENABLED=true
PHOENIX_SAMPLING_RATE=0.05  # 5% é‡‡æ ·
PHOENIX_COLLECTOR_ENDPOINT=http://prod-phoenix:4317
PHOENIX_PROJECT_NAME=knowledge-weaver-prod

# Langfuse - ä¸»è¦ç›‘æ§
LANGFUSE_ENABLED=true
LANGFUSE_HOST=https://cloud.langfuse.com
LANGFUSE_PUBLIC_KEY=pk_prod_xxx
LANGFUSE_SECRET_KEY=sk_prod_xxx
```

---

## æ€§èƒ½å¼€é”€

### å•ç‹¬ä½¿ç”¨

- **Phoenix alone**: < 1-2% å»¶è¿Ÿå¢åŠ 
- **Langfuse alone**: < 2-3% å»¶è¿Ÿå¢åŠ 

### åŒæ—¶ä½¿ç”¨

- **Both enabled**: < 3-5% å»¶è¿Ÿå¢åŠ 
- **é‡‡æ ·å**: < 1-2% å»¶è¿Ÿå¢åŠ 

**ç»“è®º**ï¼šå¼€é”€å¯ä»¥æ¥å—ï¼Œå°¤å…¶æ˜¯é‡‡æ ·åã€‚

---

## æœ€ä½³å®è·µæ€»ç»“

### âœ… æ¨èåšæ³•

1. **å¼€å‘é˜¶æ®µ**ï¼šåªç”¨ Phoenix
   - å¿«é€Ÿå®éªŒ
   - æ— éœ€äº‘æœåŠ¡
   - å®Œå…¨å…è´¹

2. **æµ‹è¯•é˜¶æ®µ**ï¼šä¸¤ä¸ªéƒ½å¯ç”¨
   - Phoenixï¼šæŠ€æœ¯æŒ‡æ ‡
   - Langfuseï¼šä¸šåŠ¡æŒ‡æ ‡

3. **ç”Ÿäº§é˜¶æ®µ**ï¼šä¸»è¦ç”¨ Langfuse
   - Phoenix å¯é€‰ï¼ˆé‡‡æ ·ï¼‰
   - Langfuse ç”¨äºç›‘æ§

4. **å‘ç°é—®é¢˜**ï¼šå›åˆ° Phoenix
   - è¯Šæ–­å’Œä¼˜åŒ–
   - è¯„ä¼°æ”¹è¿›æ•ˆæœ

### âŒ ä¸æ¨èåšæ³•

1. ~~ç”Ÿäº§ç¯å¢ƒå¯ç”¨ Phoenix å…¨é‡è¿½è¸ª~~
   - å¼€é”€è¾ƒå¤§
   - ä¸éœ€è¦å®éªŒåŠŸèƒ½

2. ~~å¼€å‘é˜¶æ®µç”¨ Langfuse~~
   - å®éªŒåŠŸèƒ½å¼±
   - éœ€è¦äº‘æœåŠ¡

3. ~~åŒæ—¶ä½¿ç”¨ä½†ä¸é‡‡æ ·~~
   - æ€§èƒ½å¼€é”€å åŠ 
   - æ•°æ®å†—ä½™

---

## æ•°æ®æµå‘

```
ç”¨æˆ·è¯·æ±‚
  â†“
åº”ç”¨ä»£ç 
  â†“
OpenAI Client
  â”œâ”€â†’ Phoenix (OpenTelemetry)
  â”‚     â”œâ”€ æŠ€æœ¯æŒ‡æ ‡ï¼ˆå»¶è¿Ÿã€Tokenï¼‰
  â”‚     â”œâ”€ Prompt/Response
  â”‚     â””â”€ å®éªŒæ•°æ®
  â”‚
  â””â”€â†’ Langfuse (Wrapper)
        â”œâ”€ ä¸šåŠ¡æŒ‡æ ‡ï¼ˆæˆæœ¬ã€ç”¨æˆ·ï¼‰
        â”œâ”€ Prompt/Response
        â””â”€ åˆ†ææ•°æ®
```

**é‡è¦**ï¼šä¸¤ä¸ªç³»ç»Ÿçš„æ•°æ®æ˜¯ç‹¬ç«‹çš„ï¼Œäº’ä¸å½±å“ã€‚

---

## å·¥å…·é€‰æ‹©å†³ç­–æ ‘

```
éœ€è¦åšä»€ä¹ˆï¼Ÿ
â”‚
â”œâ”€ å¼€å‘æ–°åŠŸèƒ½ / ä¼˜åŒ– Prompt
â”‚  â””â”€â†’ ä½¿ç”¨ Phoenix âœ…
â”‚
â”œâ”€ ç”Ÿäº§ç¯å¢ƒç›‘æ§
â”‚  â””â”€â†’ ä½¿ç”¨ Langfuse âœ…
â”‚
â”œâ”€ è¯„ä¼°å’Œ A/B æµ‹è¯•
â”‚  â””â”€â†’ ä½¿ç”¨ Phoenix âœ…
â”‚
â”œâ”€ æˆæœ¬åˆ†æå’Œè¿½è¸ª
â”‚  â””â”€â†’ ä½¿ç”¨ Langfuse âœ…
â”‚
â”œâ”€ è¯Šæ–­ç”Ÿäº§é—®é¢˜
â”‚  â”œâ”€ å…ˆçœ‹ Langfuseï¼ˆå‘ç°é—®é¢˜ï¼‰
â”‚  â””â”€ å†ç”¨ Phoenixï¼ˆè¯Šæ–­å’Œä¿®å¤ï¼‰
â”‚
â””â”€ å…¨æµç¨‹è¦†ç›–
   â””â”€â†’ ä¸¤ä¸ªéƒ½ç”¨ âœ…
```

---

**æ›´æ–°æ—¥æœŸ**: 2026-01-26
**ç»´æŠ¤è€…**: Sheldon
